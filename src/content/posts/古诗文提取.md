---
title: å¤è¯—æ–‡æå–ä¸ºmd
published: 2025-10-15
description: 'å¤è¯—è¯æ–‡ç« æå–'
image: ''
tags: [poems]
category: 'poems'
draft: true 
lang: ''
---

```python
import requests
from bs4 import BeautifulSoup
import re
import os
from urllib.parse import urlparse

def ensure_chinese_directory():
    """ç¡®ä¿ä¸­æ–‡å­—ç¬¦ç›®å½•å­˜åœ¨"""
    directory = "è¯—è¯æ–‡æ¡£"
    if not os.path.exists(directory):
        os.makedirs(directory)
    return directory

def extract_pinyin_from_html(html_content):
    """ä»HTMLå†…å®¹ä¸­æå–æ‹¼éŸ³ä¿¡æ¯"""
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # æŸ¥æ‰¾æ‰€æœ‰rubyæ ‡ç­¾
    ruby_tags = soup.find_all('ruby')
    pinyin_map = {}
    
    for ruby in ruby_tags:
        # è·å–æ±‰å­—
        chinese_char = ruby.get_text(strip=True)
        # è·å–æ‹¼éŸ³
        rt_tag = ruby.find('rt')
        if rt_tag:
            pinyin = rt_tag.get_text(strip=True)
            pinyin_map[chinese_char] = pinyin
    
    return pinyin_map

def add_pinyin_to_text(text, pinyin_map):
    """ä½¿ç”¨ä»ç½‘é¡µæå–çš„æ‹¼éŸ³æ˜ å°„ä¸ºæ–‡æœ¬æ·»åŠ æ‹¼éŸ³æ ‡æ³¨"""
    result = ""
    for char in text:
        if char in pinyin_map:
            result += f'<ruby>{char}<rt>{pinyin_map[char]}</rt></ruby>'
        else:
            result += char
    return result

def extract_author_with_pinyin(soup):
    """ä¸“é—¨æå–ä½œè€…ä¿¡æ¯ï¼ŒåŒ…æ‹¬å®Œæ•´çš„æ‹¼éŸ³"""
    # æŸ¥æ‰¾ä½œè€…æ ‡ç­¾
    author_tag = soup.find("p", class_="card-subtitle mb-2 text-muted mr-1")
    if not author_tag:
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„ç±»å
        author_tag = soup.find("p", class_=re.compile(r"card-subtitle|text-muted|author"))
    
    if author_tag:
        # ç›´æ¥è·å–ä½œè€…HTMLå†…å®¹ï¼Œä¿ç•™æ‹¼éŸ³æ ‡æ³¨
        author_html = str(author_tag)
        
        # æ¸…ç†HTMLæ ‡ç­¾ï¼Œä½†ä¿ç•™rubyæ ‡ç­¾
        author_html = re.sub(r'\sclass=".*?"', '', author_html)
        author_html = re.sub(r'\sstyle=".*?"', '', author_html)
        
        # æå–çº¯æ–‡æœ¬ä½œè€…åç”¨äºæ˜¾ç¤º
        author_text = author_tag.get_text(strip=True)
        author_text = re.sub(r'[ã€ã€‘\[\]]', '', author_text)
        
        return author_text, author_html
    
    return "æœªçŸ¥ä½œè€…", "æœªçŸ¥ä½œè€…"

def extract_poem_info(url):
    """
    ä»è¯—è¯ç½‘é¡µæå–æ‰€æœ‰ä¿¡æ¯
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        resp.encoding = "utf-8"
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        
        # æå–æ ‡é¢˜
        title_tag = soup.find("h2", class_="text-center")
        title = title_tag.get_text(strip=True) if title_tag else "æœªçŸ¥æ ‡é¢˜"
        title = re.sub(r"-æ‹¼éŸ³ç‰ˆ-.*", "", title).strip()
        
        # ä¸“é—¨æå–ä½œè€…ä¿¡æ¯å’Œæ‹¼éŸ³
        author, author_html = extract_author_with_pinyin(soup)
        
        # ä»æ•´ä¸ªé¡µé¢æå–æ‹¼éŸ³æ˜ å°„
        pinyin_map = extract_pinyin_from_html(resp.text)
        
        # æå–æ‹¼éŸ³æ­£æ–‡
        pinyin_section = soup.find("div", class_="pinyin")
        if not pinyin_section:
            ruby_tags = soup.find_all("ruby")
            if ruby_tags:
                for ruby in ruby_tags[:1]:
                    parent = ruby.find_parent("div")
                    if parent and len(parent.find_all("ruby")) > 3:
                        pinyin_section = parent
                        break
        
        # æ ¼å¼åŒ–æ‹¼éŸ³æ®µè½ - æ›´å‡†ç¡®åœ°ç§»é™¤é‡å¤çš„ä½œè€…ä¿¡æ¯
        pinyin_paragraphs = []
        if pinyin_section:
            paragraphs = pinyin_section.find_all("p")
            
            # åˆ›å»ºä¸€ä¸ªé›†åˆæ¥è·Ÿè¸ªå·²ç»å¤„ç†è¿‡çš„ä½œè€…ä¿¡æ¯
            processed_authors = set()
            # æå–çº¯æ–‡æœ¬ä½œè€…åç”¨äºæ¯”è¾ƒ
            author_clean = re.sub(r'[()ï¼ˆï¼‰]', '', author).strip()
            
            for p in paragraphs:
                html = str(p)
                html = re.sub(r'\sclass=".*?"', '', html)
                html = re.sub(r'\sstyle=".*?"', '', html)
                
                paragraph_text = p.get_text(strip=True)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºä½œè€…ä¿¡æ¯æ®µè½
                # ä½œè€…ä¿¡æ¯é€šå¸¸åŒ…å«æœä»£å’Œä½œè€…åï¼Œå¯èƒ½ç”¨æ‹¬å·æ‹¬èµ·æ¥
                is_author_paragraph = (
                    '(' in paragraph_text and ')' in paragraph_text and
                    len(paragraph_text) < 20  # ä½œè€…æ®µè½é€šå¸¸è¾ƒçŸ­
                )
                
                # å¦‚æœæ˜¯ä½œè€…ä¿¡æ¯æ®µè½ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
                if is_author_paragraph:
                    # æ ‡å‡†åŒ–ä½œè€…ä¿¡æ¯ä»¥ä¾¿æ¯”è¾ƒ
                    normalized_author = re.sub(r'[()ï¼ˆï¼‰\s]', '', paragraph_text)  # ç§»é™¤æ‰€æœ‰æ‹¬å·å’Œç©ºæ ¼
                    
                    # å¦‚æœè¿™ä¸ªä½œè€…ä¿¡æ¯å·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡è¿™ä¸ªæ®µè½
                    if normalized_author in processed_authors:
                        continue
                    
                    # æˆ–è€…å¦‚æœè¿™ä¸ªä½œè€…ä¿¡æ¯ä¸é¡µé¢æå–çš„ä½œè€…åŒ¹é…ï¼Œä¹Ÿè·³è¿‡
                    author_clean_normalized = re.sub(r'[()ï¼ˆï¼‰\s]', '', author_clean)
                    if normalized_author == author_clean_normalized:
                        continue
                    
                    # å¦åˆ™æ ‡è®°ä¸ºå·²å¤„ç†ï¼Œå¹¶ä¿ç•™è¿™ä¸ªæ®µè½
                    processed_authors.add(normalized_author)
                    # ä½œè€…ä¿¡æ¯ä½¿ç”¨å±…ä¸­å¯¹é½
                    html = html.replace('<p', '<p align="center"')
                else:
                    # æ­£æ–‡éƒ¨åˆ†ä½¿ç”¨ä¸¤ç«¯å¯¹é½
                    html = html.replace('<p', '<p align="justify"')
                
                pinyin_paragraphs.append(html)
        
        # æå–æ³¨é‡Šã€è¯‘æ–‡å’Œèµæ
        sections = soup.find_all("h3")
        content_dict = {"æ³¨é‡Š": "", "ç™½è¯è¯‘æ–‡": "", "èµæ": ""}
        
        for h3 in sections:
            section_title = h3.get_text(strip=True)
            if section_title in content_dict:
                # æŸ¥æ‰¾å†…å®¹å®¹å™¨
                content_div = h3.find_next_sibling("div")
                if not content_div:
                    content_div = h3.find_next_sibling("p")
                
                if content_div:
                    # å¤„ç†å†…å®¹ - ç›´æ¥æå–æ–‡æœ¬å¹¶æŒ‰æ®µè½åˆ†å‰²
                    text_content = content_div.get_text()
                    
                    # æŒ‰æ®µè½åˆ†å‰² - ä½¿ç”¨æ›´å‡†ç¡®çš„åˆ†å‰²æ–¹æ³•
                    # å…ˆæŒ‰ä¸¤ä¸ªå…¨è§’ç©ºæ ¼åˆ†å‰²ï¼ˆè¿™æ˜¯ä¸­æ–‡æ®µè½çš„å¸¸è§æ ¼å¼ï¼‰
                    paragraphs = re.split(r'ã€€ã€€', text_content)
                    # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å¹¶å»é™¤æ¯ä¸ªæ®µè½çš„é¦–å°¾ç©ºæ ¼
                    cleaned_paragraphs = [p.strip() for p in paragraphs if p.strip()]
                    
                    # å¦‚æœåˆ†å‰²åæ²¡æœ‰æ®µè½ï¼Œå°è¯•æŒ‰æ¢è¡Œåˆ†å‰²
                    if not cleaned_paragraphs:
                        raw_paragraphs = text_content.split('\n')
                        cleaned_paragraphs = [p.strip() for p in raw_paragraphs if p.strip()]
                    
                    content_dict[section_title] = cleaned_paragraphs
        
        return {
            "title": title,
            "author": author,
            "author_html": author_html,  # æ·»åŠ å®Œæ•´çš„ä½œè€…HTML
            "pinyin_map": pinyin_map,
            "pinyin_paragraphs": pinyin_paragraphs,
            "annotations": content_dict["æ³¨é‡Š"],
            "translation": content_dict["ç™½è¯è¯‘æ–‡"],
            "appreciation": content_dict["èµæ"],
            "url": url
        }
        
    except Exception as e:
        print(f"æå–è¯—è¯ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return None

def format_annotations_as_ordered_list(annotations_text):
    """å°†æ³¨é‡Šæ ¼å¼åŒ–ä¸ºæœ‰åºåˆ—è¡¨"""
    if not annotations_text or (isinstance(annotations_text, list) and not annotations_text):
        return "æš‚æ— æ³¨é‡Š"
    
    # å¦‚æœæ³¨é‡Šæ˜¯åˆ—è¡¨å½¢å¼ï¼Œå…ˆåˆå¹¶
    if isinstance(annotations_text, list):
        annotations_text = " ".join(annotations_text)
    
    if "æ‹¼éŸ³æœ‰è¯¯" in annotations_text:
        return "æš‚æ— æ³¨é‡Š"
    
    # åˆ†å‰²æ³¨é‡Šé¡¹ - å°è¯•å¤šç§åˆ†å‰²æ–¹å¼
    items = []
    
    # æ–¹å¼1: æŒ‰æ•°å­—åºå·åˆ†å‰² (1. 2. 3.)
    if re.search(r'\d+\.', annotations_text):
        items = re.split(r'\d+\.', annotations_text)[1:]  # å»æ‰ç¬¬ä¸€ä¸ªç©ºå…ƒç´ 
        items = [item.strip() for item in items if item.strip()]
    
    # æ–¹å¼2: æŒ‰ä¸­æ–‡æ•°å­—åˆ†å‰² (ä¸€ã€ äºŒã€ ä¸‰ã€)
    elif re.search(r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ã€', annotations_text):
        items = re.split(r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ã€', annotations_text)[1:]
        items = [item.strip() for item in items if item.strip()]
    
    # æ–¹å¼3: æŒ‰å¥å·åˆ†å‰²ï¼Œä½†ä¿ç•™è¾ƒé•¿çš„å†…å®¹
    else:
        # å°è¯•æŒ‰å¥å·åˆ†å‰²ï¼Œä½†è¿‡æ»¤æ‰å¤ªçŸ­çš„ç‰‡æ®µ
        parts = re.split(r'(?<=[ã€‚ï¼›;])', annotations_text)
        items = [part.strip() for part in parts if len(part.strip()) > 5]
    
    # å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½æ²¡æœ‰å¾—åˆ°åˆé€‚çš„é¡¹ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
    if not items:
        return annotations_text
    
    # æ ¼å¼åŒ–ä¸ºæœ‰åºåˆ—è¡¨
    formatted_list = []
    for i, item in enumerate(items, 1):
        # æ¸…ç†æ–‡æœ¬å¹¶æ·»åŠ åºå·
        cleaned_item = re.sub(r'^\s*[\(ï¼ˆ][^\)ï¼‰]+[\)ï¼‰]\s*', '', item)  # ç§»é™¤å¯èƒ½å­˜åœ¨çš„æ‹¬å·å†…å®¹
        formatted_list.append(f"{i}. {cleaned_item}")
    
    return "\n".join(formatted_list)

def format_translation(translation_paragraphs):
    """æ ¼å¼åŒ–ç™½è¯è¯‘æ–‡ - æ¯ä¸ªæ®µè½ä»¥ä¸¤ä¸ªå…¨è§’ç©ºæ ¼å¼€å¤´ï¼Œé™¤æœ€åä¸€æ®µå¤–æœ«å°¾éƒ½æ·»åŠ ä¸¤ä¸ªåŠè§’ç©ºæ ¼"""
    if not translation_paragraphs or (isinstance(translation_paragraphs, list) and not translation_paragraphs):
        return "æš‚æ— è¯‘æ–‡"
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
    if isinstance(translation_paragraphs, str):
        if "æ‹¼éŸ³æœ‰è¯¯" in translation_paragraphs:
            return "æš‚æ— è¯‘æ–‡"
        # å°è¯•æŒ‰æ®µè½åˆ†å‰²
        paragraphs = re.split(r'ã€€ã€€', translation_paragraphs)
        translation_paragraphs = [p.strip() for p in paragraphs if p.strip()]
    
    formatted_paragraphs = []
    
    for i, para in enumerate(translation_paragraphs):
        para = para.strip()
        if para:
            # æ¯ä¸ªæ®µè½ä»¥ä¸¤ä¸ªå…¨è§’ç©ºæ ¼å¼€å¤´
            formatted_para = "ã€€ã€€" + para
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ®µè½ï¼Œåœ¨æœ«å°¾æ·»åŠ ä¸¤ä¸ªåŠè§’ç©ºæ ¼
            if i < len(translation_paragraphs) - 1:
                formatted_para += "  "  # ä¸¤ä¸ªåŠè§’ç©ºæ ¼
            
            formatted_paragraphs.append(formatted_para)
    
    # ä½¿ç”¨æ¢è¡Œç¬¦è¿æ¥æ®µè½
    return "\n".join(formatted_paragraphs)

def format_appreciation(appreciation_paragraphs):
    """æ ¼å¼åŒ–èµæ - æ¯ä¸ªæ®µè½ä»¥ä¸¤ä¸ªå…¨è§’ç©ºæ ¼å¼€å¤´ï¼Œé™¤æœ€åä¸€æ®µå¤–æœ«å°¾éƒ½æ·»åŠ ä¸¤ä¸ªåŠè§’ç©ºæ ¼"""
    if not appreciation_paragraphs or (isinstance(appreciation_paragraphs, list) and not appreciation_paragraphs):
        return "æš‚æ— èµæ"
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
    if isinstance(appreciation_paragraphs, str):
        if "æ‹¼éŸ³æœ‰è¯¯" in appreciation_paragraphs:
            return "æš‚æ— èµæ"
        # å°è¯•æŒ‰æ®µè½åˆ†å‰²
        paragraphs = re.split(r'ã€€ã€€', appreciation_paragraphs)
        appreciation_paragraphs = [p.strip() for p in paragraphs if p.strip()]
    
    formatted_paragraphs = []
    
    for i, para in enumerate(appreciation_paragraphs):
        para = para.strip()
        if para:
            # æ¯ä¸ªæ®µè½ä»¥ä¸¤ä¸ªå…¨è§’ç©ºæ ¼å¼€å¤´
            formatted_para = "ã€€ã€€" + para
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ®µè½ï¼Œåœ¨æœ«å°¾æ·»åŠ ä¸¤ä¸ªåŠè§’ç©ºæ ¼
            if i < len(appreciation_paragraphs) - 1:
                formatted_para += "  "  # ä¸¤ä¸ªåŠè§’ç©ºæ ¼
            
            formatted_paragraphs.append(formatted_para)
    
    # ä½¿ç”¨æ¢è¡Œç¬¦è¿æ¥æ®µè½
    return "\n".join(formatted_paragraphs)

def create_markdown(poem_info):
    """æ ¹æ®æå–çš„ä¿¡æ¯åˆ›å»ºMarkdownæ–‡ä»¶"""
    title = poem_info["title"]
    author = poem_info["author"]
    pinyin_map = poem_info["pinyin_map"]
    
    # ä¸ºæ ‡é¢˜æ·»åŠ æ‹¼éŸ³ï¼ˆä½¿ç”¨ä»ç½‘é¡µæå–çš„æ‹¼éŸ³æ˜ å°„ï¼‰
    title_with_pinyin = add_pinyin_to_text(title, pinyin_map)
    
    # ä½¿ç”¨ç›´æ¥ä»ç½‘é¡µæå–çš„ä½œè€…HTMLï¼Œç¡®ä¿æ‹¼éŸ³å®Œæ•´
    author_with_pinyin = poem_info["author_html"]
    
    # æ„å»ºMarkdownå†…å®¹
    md_content = f"""# å…¨æ–‡æ‹¼éŸ³

<p align="center"><strong>{title_with_pinyin}</strong></p>
"""
    
    if author_with_pinyin and author_with_pinyin != "æœªçŸ¥ä½œè€…":
        # ä½¿ç”¨å±…ä¸­å¯¹é½
        author_with_pinyin = author_with_pinyin.replace('<p', '<p align="center"')
        md_content += f'{author_with_pinyin}\n\n'
    
    # æ·»åŠ æ‹¼éŸ³æ®µè½
    if poem_info["pinyin_paragraphs"]:
        md_content += "\n\n".join(poem_info["pinyin_paragraphs"]) + "\n\n"
    else:
        md_content += "> âš ï¸ æ‹¼éŸ³æ­£æ–‡æœªæŠ“å–åˆ°ï¼Œå¯èƒ½æ˜¯ç½‘é¡µç»“æ„å˜åŒ–ã€‚\n\n"
    
    # æ·»åŠ æ³¨é‡Šï¼ˆæœ‰åºåˆ—è¡¨ï¼‰
    annotations_content = format_annotations_as_ordered_list(poem_info["annotations"])
    
    # æ·»åŠ ç™½è¯è¯‘æ–‡
    translation_content = format_translation(poem_info["translation"])
    
    # æ·»åŠ èµæ
    appreciation_content = format_appreciation(poem_info["appreciation"])
    
    md_content += f"""# æ³¨é‡Š

{annotations_content}

# ç™½è¯è¯‘æ–‡

{translation_content}

# èµæ

{appreciation_content}

---

*æœ¬æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆäºè¯—è¯ä¹ç½‘ç«™*
*åŸæ–‡é“¾æ¥: {poem_info["url"]}*
"""
    
    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"{title} - {author}.md"
    filename = re.sub(r"[\\/:*?\"<>|]", "_", filename)
    
    # ä¿å­˜æ–‡ä»¶
    directory = ensure_chinese_directory()
    filepath = os.path.join(directory, filename)
    
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(md_content)
    
    return filepath

def process_poem_url(url):
    """å¤„ç†å•ä¸ªè¯—è¯URL"""
    print(f"æ­£åœ¨å¤„ç†: {url}")
    
    # æå–è¯—è¯ä¿¡æ¯
    poem_info = extract_poem_info(url)
    if not poem_info:
        print(f"âŒ æ— æ³•æå–è¯—è¯ä¿¡æ¯: {url}")
        return None
    
    # åˆ›å»ºMarkdownæ–‡ä»¶
    filepath = create_markdown(poem_info)
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"âœ… å·²ç”Ÿæˆ: {filepath}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ ‡é¢˜: {poem_info['title']}")
    print(f"   ä½œè€…: {poem_info['author']}")
    print(f"   æ‹¼éŸ³æ˜ å°„è¡¨å¤§å°: {len(poem_info['pinyin_map'])}")
    print(f"   æ‹¼éŸ³æ®µè½æ•°: {len(poem_info['pinyin_paragraphs'])}")
    
    # å¤„ç†æ³¨é‡Šã€è¯‘æ–‡å’Œèµæçš„ç»Ÿè®¡ä¿¡æ¯
    annotations = poem_info['annotations']
    translation = poem_info['translation']
    appreciation = poem_info['appreciation']
    
    has_annotations = False
    if isinstance(annotations, list):
        has_annotations = len(annotations) > 0 and not any("æ‹¼éŸ³æœ‰è¯¯" in str(a) for a in annotations)
    else:
        has_annotations = annotations and "æ‹¼éŸ³æœ‰è¯¯" not in annotations
    
    has_translation = False
    if isinstance(translation, list):
        has_translation = len(translation) > 0 and not any("æ‹¼éŸ³æœ‰è¯¯" in str(t) for t in translation)
    else:
        has_translation = translation and "æ‹¼éŸ³æœ‰è¯¯" not in translation
    
    has_appreciation = False
    if isinstance(appreciation, list):
        has_appreciation = len(appreciation) > 0 and not any("æ‹¼éŸ³æœ‰è¯¯" in str(a) for a in appreciation)
    else:
        has_appreciation = appreciation and "æ‹¼éŸ³æœ‰è¯¯" not in appreciation
    
    print(f"   æ³¨é‡Š: {'æœ‰' if has_annotations else 'æ— '}")
    print(f"   è¯‘æ–‡: {'æœ‰' if has_translation else 'æ— '}")
    print(f"   èµæ: {'æœ‰' if has_appreciation else 'æ— '}")
    
    return filepath

def main():
    """ä¸»å‡½æ•° - å¯ä»¥å¤„ç†å•ä¸ªæˆ–å¤šä¸ªURL"""
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å¤šä¸ªURL
    urls = [
        "https://www.shicile.com/detail/7360098413110", 	"https://www.shicile.com/detail/1290299354172", 
        # å¯ä»¥æ·»åŠ æ›´å¤šURLï¼Œä¾‹å¦‚:
        # "https://www.shicile.com/detail/123456789",  # å…¶ä»–è¯—è¯
    ]
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šURLï¼Œå¯ä»¥æ‰‹åŠ¨è¾“å…¥
    if not urls:
        url = input("è¯·è¾“å…¥è¯—è¯URL: ").strip()
        if url:
            urls = [url]
    
    # å¤„ç†æ¯ä¸ªURL
    for url in urls:
        try:
            process_poem_url(url)
            print("-" * 50)
        except Exception as e:
            print(f"âŒ å¤„ç†URLæ—¶å‡ºé”™ {url}: {e}")
            print("-" * 50)

if __name__ == "__main__":
    main()
```
